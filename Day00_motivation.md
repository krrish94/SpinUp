# Day 00: Motivation

So, I just got to know that [OpenAI](https://openai.com/) released **[Spinning Up in DeepRL](https://spinningup.openai.com/en/latest/)**, a collection of simplified code, exercises, and a curated list of about a 100 influential papers in the field. It's like _RL on-a-platter_ for a noob like me. That's what got me thinking, "Hmm... what about I take this up as a 100-day thing? Where, I can do just about an hour or two (or sometimes a little more or a little less) of Spinning Up everyday, and hope to become [competent](https://en.wikipedia.org/wiki/Dreyfus_model_of_skill_acquisition) with RL by the end of it all".


## Motto/Philosophy

I looking at DeepRL as a future research avenue. My primary/current research agenda involves enhancing the state of the art of robotic perception capabilities. I envision mature perception modules as major players in powering RL techniques of the future. 

According to my (pre-conceived) notions of RL, it does a fairly decent job of task-specific policy learning (under controlled scenarios, for now). It is capable of connects perception to action. But as far as my understanding goes, most RL agents attempt to learn tasks from percepts, which seems somewhat akin to _reinventing the wheel_ to me. To me, RL is a tool that I would use to connect the outputs of a perceptual model of the world to an agent that learns a policy to solve a specified set of tasks.

And to establish that connection, I need to be fairly capable of developing RL techniques and more importantly, understand the tricks of the trade (tweaks, barebones of the code, etc.). I find this series especially intriguing to begin with, as it's targeted at beginners in the field, and also because of the incredible amount of effort that I feel would've gone in, in developing a unified exposure to several RL algorithms.

## (Current) plan of action

(Emphasis on current, because my plans tend to change when I'm delving deeper into things.)
1. I'm a PyTorch guy, but this also seems to be a good way for me to get to understand TF much better (phew, long overdue!). This now becomes my path of least resistance to learning tensorflow.
2. I tend to learn more as I re-implement stuff. I'd love to re-implement most of these techniques in PyTorch, to enhance my understanding. 
3. Also, critically, I'm looking to build a flair for the underlying theory/assumptions. So, I also plan on reading a paper a day. In the end, I'm gonna end up with a repo of paper summaries of landmark RL papers, so that's a huge plus.
4. I am looking to establish a parallel reading list of my own, along the course of spinning up. That'll be a great feedback for the major review that OpenAI plans to hold in April 2019. What worked/didn't work for me would help several others who would go on to pursue this curriculum. That's my giving back opportunity.
5. Importantly, everyday, write at least one such note-to-self. Could prove useful in the long run. Also, makes me accountable and keeps the motivation going.

Here's to 100 days of RL ...
